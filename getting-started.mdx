---
title: "Getting Started"
description:
  "We're glad to see you here. Today we're going to install SDF and create a
  hello world project. Let's get started."
---

## Installing SDF

<Tabs>
  <Tab title="Binary Download">

    Our install script will first check your operating system and architecture,
    then install the latest version of SDF and its dependencies for your system.
    The `sdf` command will also be added to your path.


    ```bash
    curl -LSfs https://cdn.sdf.com/releases/download/install.sh | bash -s
    ```

  </Tab>
</Tabs>

### Verify Installation

To verify that SDF is installed correctly, run the following command:

```bash
sdf --help
```

```bash
SDF's modular SQL

Usage: sdf <COMMAND>

Commands:
  configure  Initialize your SDF environment
  new        Create a new SDF workspace at PATH
  clean      Remove generated SDF artifacts in workspace
  build      Build, run, and save SDF queries
  describe   Describe SDF table schemas
  deploy     Create a deployment and post it to the SDF service
  view       View existing table content
  trace      Display lineage for a given column
  system     System maintenance and generation of reference documentation
  auth       Manage credentials and tokens
  help       Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version
```

For more on installing SDF, see [Install SDF](/guide/install).

## Creating a Project

To create a new project, run the following command:

```bash
sdf new hello_world
```

After running the command, you should see the following output:

```bash
    Created hello_world/.gitignore
    Created hello_world/src/main.sql
    Created hello_world/workspace.sdf.yml
   Finished new in 0.000 secs
```

This will create a new directory with the name of your project. In this case,
that's `hello_world`. The directory will contain an `workspace.sdf.yml` file,
which is the main configuration file for your project. For more on this, see our
[workspaces guide](guide/workspace). Your new directory will also contain a
`src` directory with a `main.sdf` file, which is the entry point for your
project and the sql file we'll be statically analyzing and executing locally.
Next, let's take a deeper look at your project.

## Exploring Your Project

Next we'll run two core commands in SDF:
[sdf describe](/guide/sdf_cli_2_basics#sdf-describe) and
[sdf build](/guide/sdf_cli_2_basics#sdf-build). Describing our project will
_statically_ analyze the query and tell you about the table schemas and
column-level lineage. Building will run the query locally right on your machine.
Let's give it a go.

First we'll try `sdf describe`

```bash
sdf describe
```

```bash
  Analyzing hello_world.pub.main (./src/main.sql)

Schema hello_world.pub.main
+-------------+-----------+-------------+------------+
| column_name | data_type | is_nullable | classifier |
+-------------+-----------+-------------+------------+
| column      | varchar   | false       |            |
+-------------+-----------+-------------+------------+
    Written .sdfcache/all.sdf.yml
   Finished describe in 0.194 secs
```

As you can see from the output, SDF has statically analyzed the query and
determined there's a single non-nullable column named `column` and its of type
`varchar`. You'll also see an empty `classifier` block in the output. This is
for metadata we'll attach to columns, but we'll get to that later.

Next let's try `sdf build` to run the query locally.

```bash
sdf build
```

```bash
   Building hello_world.pub.main (./src/main.sql)

Table hello_world.pub.main
+--------+
| column |
+--------+
| hello  |
+--------+
1 rows.

    Written .sdfcache/hello_world/pub/main
    Written .sdfcache/all.sdf.yml
   Finished build in 0.222 secs
```

That's right - SDF just ran the query locally on your machine, and yes it did
take a tenth of a second. The output is a table with a single column named
`column` and a single row with the value `hello`. This data was defined as a
constant within the SQL file itself. In a real case, you'd be querying a data
lake or warehouse, and we'd do some clever sampling work to cache the data
locally so you could work with it fully local and offline.

In this guide we showed you just how easy it is to install SDF and run your
first query. Next you can move on to our
[SDF Basics](/docs/guide/sdf_cli_2_basics) guide to learn more about the SDF CLI
and learn how to work with real data.
